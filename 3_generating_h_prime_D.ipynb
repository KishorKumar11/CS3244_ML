{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da93a2d-2c12-42a4-b3d2-700d5b006f34",
   "metadata": {},
   "source": [
    "# Generation of H'(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4494535-5a2b-466a-a17f-c1d7478558b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report \n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef6f9d-02c2-4711-b233-fc7565f2bef7",
   "metadata": {},
   "source": [
    "In this section we will be using the meta features that were generated for the dataset D and the model we selected back in part 1 to derive select us a model for the respective dataset D. We will then analyse the performance of the hyperparameter tuned model and the derived model through means of t-testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650d37c1-059c-48d8-a87c-b1a31298ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_meta_features =np.array([0.33185840707964603, 0.01327433628318584, 0.0, 0.12389380530973451, 0.5309734513274337, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766bd182-da1f-4d8d-b8b6-8a813747f293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33185841, 0.01327434, 0.        , 0.12389381, 0.53097345,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_meta_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0425aa94-ffd0-408a-8043-a4f7193fb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('h_star_d.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aed229c-9f38-4990-bf94-122023bb3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_star_d = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e4c99b-fd31-4416-a5a4-ceb5501255b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_prime_d = h_star_d.predict([dataset_meta_features])\n",
    "h_prime_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c1c20-6de3-419a-95e0-a7b0f1b36fc6",
   "metadata": {},
   "source": [
    "As you can see from the above model the, predicted label is 1. This implies that the model selected for this particular dataset is a K-Nearest Neighbour algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a7ecb-1ab7-47eb-a24a-a94bedb99a80",
   "metadata": {},
   "source": [
    "## Performing evaluation test for the h'(D) model = KNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d8eec4-d705-45ee-b66e-1ddc7eff2c63",
   "metadata": {},
   "source": [
    "# Importing Meta-Learning Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3044d13e-0416-4f27-a056-8098d982f73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_0</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>beta_3</th>\n",
       "      <th>beta_4</th>\n",
       "      <th>beta_5</th>\n",
       "      <th>beta_6</th>\n",
       "      <th>beta_7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.116358</td>\n",
       "      <td>0.134907</td>\n",
       "      <td>0.278246</td>\n",
       "      <td>0.470489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.096939</td>\n",
       "      <td>0.210459</td>\n",
       "      <td>0.269133</td>\n",
       "      <td>0.423469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067696</td>\n",
       "      <td>0.157957</td>\n",
       "      <td>0.483373</td>\n",
       "      <td>0.290974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.132486</td>\n",
       "      <td>0.328494</td>\n",
       "      <td>0.453721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.262215</td>\n",
       "      <td>0.288274</td>\n",
       "      <td>0.423453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335975</td>\n",
       "      <td>0.664025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322368</td>\n",
       "      <td>0.677632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.062405</td>\n",
       "      <td>0.138508</td>\n",
       "      <td>0.512938</td>\n",
       "      <td>0.286149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.318792</td>\n",
       "      <td>0.677852</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344648</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       beta_0    beta_1    beta_2    beta_3  beta_4  beta_5  beta_6  beta_7  \\\n",
       "0    0.116358  0.134907  0.278246  0.470489     0.0     0.0     0.0     0.0   \n",
       "1    0.096939  0.210459  0.269133  0.423469     0.0     0.0     0.0     0.0   \n",
       "2    0.067696  0.157957  0.483373  0.290974     0.0     0.0     0.0     0.0   \n",
       "3    0.085299  0.132486  0.328494  0.453721     0.0     0.0     0.0     0.0   \n",
       "4    0.026059  0.262215  0.288274  0.423453     0.0     0.0     0.0     0.0   \n",
       "..        ...       ...       ...       ...     ...     ...     ...     ...   \n",
       "221  0.000000  0.335975  0.664025  0.000000     0.0     0.0     0.0     0.0   \n",
       "222  0.000000  0.322368  0.677632  0.000000     0.0     0.0     0.0     0.0   \n",
       "223  0.062405  0.138508  0.512938  0.286149     0.0     0.0     0.0     0.0   \n",
       "224  0.001678  0.318792  0.677852  0.001678     0.0     0.0     0.0     0.0   \n",
       "225  0.000000  0.344648  0.655352  0.000000     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     label  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "..     ...  \n",
       "221      1  \n",
       "222      1  \n",
       "223      1  \n",
       "224      1  \n",
       "225      1  \n",
       "\n",
       "[226 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./meta-dataset.csv')\n",
    "dataset = dataset.iloc[:,1:]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d336d871-5d9c-419d-8472-e2b4406d0fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_0</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>beta_3</th>\n",
       "      <th>beta_4</th>\n",
       "      <th>beta_5</th>\n",
       "      <th>beta_6</th>\n",
       "      <th>beta_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.116358</td>\n",
       "      <td>0.134907</td>\n",
       "      <td>0.278246</td>\n",
       "      <td>0.470489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.096939</td>\n",
       "      <td>0.210459</td>\n",
       "      <td>0.269133</td>\n",
       "      <td>0.423469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067696</td>\n",
       "      <td>0.157957</td>\n",
       "      <td>0.483373</td>\n",
       "      <td>0.290974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.132486</td>\n",
       "      <td>0.328494</td>\n",
       "      <td>0.453721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.262215</td>\n",
       "      <td>0.288274</td>\n",
       "      <td>0.423453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335975</td>\n",
       "      <td>0.664025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322368</td>\n",
       "      <td>0.677632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.062405</td>\n",
       "      <td>0.138508</td>\n",
       "      <td>0.512938</td>\n",
       "      <td>0.286149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.318792</td>\n",
       "      <td>0.677852</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344648</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       beta_0    beta_1    beta_2    beta_3  beta_4  beta_5  beta_6  beta_7\n",
       "0    0.116358  0.134907  0.278246  0.470489     0.0     0.0     0.0     0.0\n",
       "1    0.096939  0.210459  0.269133  0.423469     0.0     0.0     0.0     0.0\n",
       "2    0.067696  0.157957  0.483373  0.290974     0.0     0.0     0.0     0.0\n",
       "3    0.085299  0.132486  0.328494  0.453721     0.0     0.0     0.0     0.0\n",
       "4    0.026059  0.262215  0.288274  0.423453     0.0     0.0     0.0     0.0\n",
       "..        ...       ...       ...       ...     ...     ...     ...     ...\n",
       "221  0.000000  0.335975  0.664025  0.000000     0.0     0.0     0.0     0.0\n",
       "222  0.000000  0.322368  0.677632  0.000000     0.0     0.0     0.0     0.0\n",
       "223  0.062405  0.138508  0.512938  0.286149     0.0     0.0     0.0     0.0\n",
       "224  0.001678  0.318792  0.677852  0.001678     0.0     0.0     0.0     0.0\n",
       "225  0.000000  0.344648  0.655352  0.000000     0.0     0.0     0.0     0.0\n",
       "\n",
       "[226 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dataset.iloc[:,:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc46ec7-aea7-4823-bbc1-6d537bfab564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "221    1\n",
       "222    1\n",
       "223    1\n",
       "224    1\n",
       "225    1\n",
       "Name: label, Length: 226, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset.iloc[:,-1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d12f71e-f08b-4229-8f8e-9451d0735f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c297f3d-c981-4af4-801e-279d859d023f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_prime_d = KNeighborsClassifier()\n",
    "h_prime_d.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30685833-c810-4554-8aab-362776100d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.69      0.94      0.79        31\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.63        46\n",
      "   macro avg       0.23      0.31      0.26        46\n",
      "weighted avg       0.47      0.63      0.54        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = h_prime_d.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b8aa5-2143-479d-bd73-7b7703de3a2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c4caf5-bdec-424d-80ee-1f8c99d8f88e",
   "metadata": {},
   "source": [
    "### Performing t-testing on the selected model and the predicted model, that h_star_d and h_prime_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f90803",
   "metadata": {},
   "source": [
    "To compare the selected and predicted model, we apply t-testing that compares the mean of the two models. A value of alpha = 0.05 implies that the null hypothesis is rejected 5 % of the time when it is in fact true. Therefore, if the p metric evaluated from t-testing between the two models is less than 0.05 then it is considered significant (the models are not similar) else it is considered insignificant (the models are similar).\n",
    "\n",
    "In our case, we were able to get p as 0.617 which is larger than alpha thus confirming that the models are similar.\n",
    "\n",
    "We also noted that the manually tuned model (KNN) is superior based on the 'accuracy' and 'weighted avg' comparison. However, t-testing has shown us that the difference between the manually tuned and predicted model is insignificant. We believe that the dataset being too small is a huge factor in this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb1a52e8-79fd-4cf0-9653-c50099547de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic: 0.533\n",
      "aplha  0.05\n",
      "p value: 0.617\n",
      "Fail to reject null hypotesis\n"
     ]
    }
   ],
   "source": [
    "t, p = paired_ttest_5x2cv(estimator1=h_star_d,estimator2=h_prime_d,X=features,\n",
    "                          y=labels)\n",
    "alpha = 0.05\n",
    "\n",
    "print('t statistic: %.3f' % t)\n",
    "print('aplha ', alpha)\n",
    "print('p value: %.3f' % p)\n",
    "\n",
    "if p > alpha:\n",
    "    print(\"Fail to reject null hypotesis\")\n",
    "else:\n",
    "    print(\"Reject null hypotesis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
